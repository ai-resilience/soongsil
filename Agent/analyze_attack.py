import json
from openai import OpenAI
import chromadb
from chromadb.utils import embedding_functions

client = OpenAI(api_key="")

chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection(name="attack_logs")

def query_chroma_hint(query_text="accuracy drop after task 9", top_k=3):
    try:
        results = collection.query(
            query_texts=[query_text],
            n_results=top_k
        )
        docs = results.get("documents", [[]])[0]
        if not docs:
            return "ChromaDBì—ì„œ ê´€ë ¨ íŒíŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return "\n".join(docs)
    except Exception as e:
        return f"ChromaDB ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def load_accuracy_matrices(filename: str):
    with open(filename, 'r', encoding='utf-8') as f:
        data = json.load(f)
    before = data["ë‹¨ê³„ 1/4: ì´ˆê¸° ëª¨ë¸ í•™ìŠµ"]["accuracy_matrix"]
    after = data["ë‹¨ê³„ 4/4: ìµœì¢… í‰ê°€"]["accuracy_matrix"]
    return before, after

def flatten_accuracy(matrix):
    return [round(row[i], 2) if i < len(row) else 0.0 for i, row in enumerate(matrix)]

def generate_gpt_prompt(before_acc, after_acc, chroma_hint: str):
    prompt = f"""
ë‹¹ì‹ ì€ ë¨¸ì‹ ëŸ¬ë‹ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ëª¨ë¸ì´ í•™ìŠµëœ ì „í›„ì˜ íƒœìŠ¤í¬ë³„ ì •í™•ë„ì…ë‹ˆë‹¤:

- ê³µê²© ì „ ì •í™•ë„ (ë§ˆì§€ë§‰ ë‹¨ê³„ ê¸°ì¤€): {before_acc}
- ê³µê²© í›„ ì •í™•ë„ (ë§ˆì§€ë§‰ ë‹¨ê³„ ê¸°ì¤€): {after_acc}

ë˜í•œ, ChromaDBì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì°¸ê³  íŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
---
{chroma_hint}
---

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤:

1. ì–´ë–¤ íƒœìŠ¤í¬ì—ì„œ ì •í™•ë„ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ í•˜ë½í–ˆìŠµë‹ˆê¹Œ?
2. ì´ í˜„ìƒì´ Brainwash ê³µê²©ì˜ íŠ¹ì§•ì— ë¶€í•©í•©ë‹ˆê¹Œ? ì•„ë‹ˆë©´ Accumulative Attackì˜ íŠ¹ì§•ì— ë¶€í•©í•©ë‹ˆê¹Œ?

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤:
{{
  "attack_type": "<ê³µê²© ì´ë¦„ ë˜ëŠ” ì—†ìŒ>",
  "attacked_tasks": [<ì •í™•ë„ í•˜ë½ task ë²ˆí˜¸ë“¤>],
  "reason": "<íŒë‹¨ ê·¼ê±° í•œêµ­ì–´ ì„¤ëª…>"
}}
"""
    return prompt

def query_gpt_analysis(prompt):
    response = client.chat.completions.create(
        model="gpt-4o",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê³µê²© ìœ í˜•ì„ íŒë‹¨í•˜ëŠ” ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1,
        max_tokens=1024
    )
    return json.loads(response.choices[0].message.content)

def main():
    before, after = load_accuracy_matrices("/home/jun/work/Agent/analysis_log_20250723_144953.json")
    before_final = flatten_accuracy(before)
    after_final = flatten_accuracy(after)

    # ChromaDBì—ì„œ ìë™ íŒíŠ¸ ì¶”ì¶œ
    chroma_hint = query_chroma_hint("accuracy drop after task 9")

    prompt = generate_gpt_prompt(before_final, after_final, chroma_hint)
    result = query_gpt_analysis(prompt)

    print("\nğŸ” ê³µê²© íŒë‹¨ ê²°ê³¼:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()